<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Matilda.js by JDvorak</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Matilda.js</h1>
        <p class="header">Matilda.js v0.0.1 -- Webscale Inference Toolkit</p>

        <ul>
          <li class="download"><a class="buttons" href="https://github.com/JDvorak/Matilda.js/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/JDvorak/Matilda.js/tarball/master">Download TAR</a></li>
          <li><a class="buttons github" href="https://github.com/JDvorak/Matilda.js">View On GitHub</a></li>
        </ul>

        <p class="header">This project is maintained by <a class="header name" href="https://github.com/JDvorak">JDvorak</a></p>


      </header>
      <section>
        <h1>Matilda.js</h1>

<h1>v0.0.2</h1>

<p>Matilda is a webscale inference toolkit. </p>

<p>This Javascript library makes it easy to perform inference on statistical topic models anywhere.
At present, Matilda performs Latent Dirichlet Allocation by way of Markov Chain Monte Carlo (MCMC).</p>

<h2>Supported Techniques</h2>

<ul>
<li>Latent Dirichlet Allocation

<ul>
<li>Sparse Gibbs Sampling</li>
</ul>
</li>
</ul><h2>Project Maturity</h2>

<p>This project is alpha. 
This is <strong>not</strong> a production library. Do not rely on it.
The interface and functionality will change drastically from week to week.<br><strong>Proceed at your own risk.</strong></p>

<h2>Dependencies</h2>

<p>This is a standalone library. </p>

<h2>Usage</h2>

<p>Matilda is a fluently structured toolkit styled after d3.js. </p>

<h4>Step 1. Instantiate a Model</h4>

<p>The basic unit of Matilda is a Matilda model.</p>

<pre><code>  var mM = new Matilda.Model();
</code></pre>

<h4>Step 2. Add Documents</h4>

<p>To train a Matilda model, you must first addDocuments. 
The method addDocuments takes an array of words.
But they need not be strings. 
A Matilda model is representation agnostic.
So long as they are in an array everything will work out.
All the items in the array are are the features that the model will be trained on.</p>

<pre><code>mM.addDocument(['Matilda','said','Never','do','anything','by','halves',
                'if','you','want','to','get','away','with','it',
                'Be','outrageous','Go','the','whole','hog','Make',
                'sure','everything','you','do','is','so','completely',
                'crazy','it','s','unbelievable']);    

mM.addDocument(['When','the','earlier','Infantry','Tank','Mark','I',
                'which','was','also','known','as','Matilda','was',
                'removed','from','service','the','Infantry',
                'Tank','Mk','II','became','known','simply','as','the','Matilda' ]);

mM.addDocument(['When','war','was','recognised','as','imminent','production','of','the',
                'Matilda','II','was','ordered','and','that','of','the','Matilda',
                'I','curtailed','The','first','order','was','placed','shortly','after',
                'trials','were','completed','with','140','ordered','from','Vulcan',
                'Foundry','in','mid','1938' ]);

mM.addDocument([ 'So','Matilda','s','strong','young','mind','continued','to',
                'grow','nurtured','by','the','voices',
                'of','all','those','authors','who',
                'had','sent','their','books','out',
                'into','the','world','like','ships','on','the','sea',
                'These','books','gave','Matilda','a','hopeful',
                'and','comforting','message','You','are','not','alone' ]);
</code></pre>

<p>But a model can also take an array of arrays.</p>

<pre><code>var document3 = ['Matilda','said','Never','do','anything','by','halves',
                'if','you','want','to','get','away','with','it',
                'Be','outrageous','Go','the','whole','hog','Make',
                'sure','everything','you','do','is','so','completely',
                'crazy','it','s','unbelievable'];   

mM.addDocument([document1, document2, document3]])  
</code></pre>

<p>Callbacks are also supported.</p>

<p>When sending multiple documents via addDocument, the callback is run after
every individual document is inserted into the object.
The callback receives an object containing model data, and the current document</p>

<pre><code>var arrayOfArrays = [document1, document2, document3]

mM.addDocument(arrayOfArrays, 
                function(dataObject, curDoc) {
                  console.log(dataObject.vocab);
                  console.log(dataObject.topics);
                  console.log(dataObject.documents);
                });
</code></pre>

<p>For natural word pre-processing <a href="https://github.com/NaturalNode/natural">NaturalNode</a> is highly recommended.</p>

<h4>Step 3. Train</h4>

<p>Now that the documents have been added, you can train your model.
By default models are set to five topics.
You can overide this defaults by using the setNumberOfTopics method.</p>

<pre><code>mM.setNumberOfTopics(3);
</code></pre>

<p>It looks like everything is good to go. 
Time to train.
Train is a method which takes a number which represents the number of iterations.
It is recommended that at least 50 iterations be made, but for this simple example 5 will do. </p>

<pre><code>mM.train(5);
</code></pre>

<p><strong>WARNING:</strong> Do not call setNumberOfTopics after training. 
Setting the Model's Topic Count <em>after</em> training will erase all training.</p>

<p>The train method also takes a callback which is called after every iteration of the training. 
The callback receives an object containing the topics, vocabulary, and document data of the model.</p>

<pre><code>mM.train(5, function(modelData){ 
  console.log(modelData.vocab);
  console.log(modelData.topics);
  console.log(modelData.documents);
});
</code></pre>

<h4>Step 4. Enjoy</h4>

<p>There are a number of features that can be drawn from the training.
A Topic by Topic matrix of correlations may be obtained by calling the topicCorrelations method. </p>

<pre><code>mM.topicCorrelations();
</code></pre>

<p>You can get back the documents containing their respective features, and their topic proportions.</p>

<pre><code>mM.getDocuments();
</code></pre>

<p>You can get an object containing all the Topics, and their words. </p>

<pre><code>mM.getTopics();
</code></pre>

<p>You can even look over the words themselves and their topic memberships.</p>

<pre><code>mM.getVocabulary();
</code></pre>

<p>But maybe you want your data more structured. 
You can get back your words organized by topic, and sorted by frequency.</p>

<pre><code>mM.getWordsByTopics();
</code></pre>

<p>Or maybe you need to organize your documents by similarity. 
Just call getSimilarDocuments and pass in one of the documents you've already added to the collection. 
In return you'll see all the documents similar to it.</p>

<pre><code>mM.getSimilarDocuments(docIndex);
</code></pre>

<h4>Step 5. Mix and Match</h4>

<p>Matilda has been made as modular and unopinionated as possible, and works well with Node libraries and client-side libraries alike.</p>

<p>Combine Matilda with MongoDB and maintain an index of entries sorted by topical similarity. 
Mix mM.topicCorrelations() with a static blogging engine and compose a topical map of your blog every regeneration.
Plug in the Google Analytics API and cluster your customers by behavioral traits.
Match it with an email service and fight spam in a whole new way, or just organize your inbox by subject.
Feed your forum into a Matilda Model and find out what your community is talking about.</p>

<p>And that's just the beginning. </p>

<p>There are big plans.</p>

<h3>Where is α and β?</h3>

<p>The smoothing factors of LDA are at present automated.</p>

<h3>Subscribe to our Newsletter!</h3>

<p>Keep up to date. Get the latest news on the next big thing delivered to your inbox. 
<a href="http://eepurl.com/yWEqf">Subscribe to our newsletter</a></p>

<h2>Roadmap</h2>

<ul>
<li>v0.0.3

<ul>
<li>File System Support</li>
</ul>
</li>
<li>v0.0.4

<ul>
<li>Convert to Belief Propagation</li>
<li>Online Fast Belief Propagation</li>
</ul>
</li>
<li>v0.0.5

<ul>
<li>Correlated Topic Model (CTM)</li>
<li>Relational Topic Model (RTM)</li>
<li>Author Topic Model (ATM)</li>
<li>Topic User Community Model (TUCM)</li>
</ul>
</li>
<li>v0.1.0

<ul>
<li>Hierarchical Pitman–Yor</li>
<li>Pachinko Allocation</li>
</ul>
</li>
<li>v0.2.0

<ul>
<li>Named Entity Recognition</li>
<li>Grasshopper</li>
</ul>
</li>
</ul><h2>Acknowledgements</h2>

<p>Matilda.js is based on <a href="https://github.com/mimno/jsLDA">LDAjs</a>, <a href="http://radimrehurek.com/gensim/">Gensim</a>, and <a href="http://mallet.cs.umass.edu/">Mallet</a>, and inspired by the works of <a href="http://www.cs.princeton.edu/%7Emimno/">David Mimno</a>, <a href="http://tedunderwood.com/">Ted Underwood</a>, <a href="http://www.cs.princeton.edu/%7Eblei/">David Blei</a>, <a href="http://www.roalddahl.com/">Roald Dahl</a>, and <a href="http://www.tankmuseum.org/ixbin/indexplus?_IXSS_=_IXMENU_%3dVehicles%26ALL%3dmatilda%26_IXACTION_%3dsummary%26%252asform%3d%252fsearch_form%252fbovtm_combined%26_IXSESSION_%3d3N23FDeXD_4%26TYPE%3darticle%26_IXFPFX_%3dtemplates%252fsummary%252f&amp;_IXFIRST_=12&amp;_IXSPFX_=templates/full/tvod/t&amp;_IXMAXHITS_=1&amp;submit-button=summary&amp;_IXSESSION_=3N23FDeXD_4&amp;_IXMENU_=Vehicles">Sir John Carden</a>.</p>
      </section>
      <footer>
        <p><small>Hosted on <a href="https://pages.github.com">GitHub Pages</a> using the Dinky theme</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
		
  </body>
</html>