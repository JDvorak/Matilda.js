{"name":"Matilda.js","tagline":"Matilda.js v0.0.1a -- Webscale Inference Toolkit","body":"# Matilda.js\r\nv0.0.1\r\n=======\r\n\r\n\r\nMatilda is a webscale inference toolkit. \r\n\r\nThis Javascript library makes it easy and convenient to perform inference on statistical topic models in both the browser and on the server. \r\nIt presently performs Latent Dirichlet Allocation by way of Markov Chain Monte Carlo (MCMC).\r\n\r\n## Supported Techniques\r\n* Latent Dirichlet Allocation\r\n  - Sparse Gibbs Sampling\r\n\r\n## Project Maturity\r\nThis project is in pre-alpha. \r\nThis is __not__ a production library. \r\nExpect the interface to change drastically from week to week, and the functionality and performance to flucuate wildly. \r\nYour code __will__ break as this project progresses. \r\nProceed at your own risk.\r\n\r\n## Dependencies\r\nThis is a standalone library. \r\n\r\n## Usage\r\n\r\nMatilda is a fluently structured toolkit styled after d3.js. \r\n\r\n#### Step 1. Instantiate a Model\r\nThe basic unit of Matilda is a Matilda model.\r\n\r\n      var mM = new Matilda.Model();\r\n\r\nA model has two core components. An engine, and a model. \r\nBy default, the engine is a Simplified Gibbs Sampler (siGS), and the model is a Latent Dirichlet Allocation (LDA) based Topic Model. \r\nAt present, this is the only model and only engine available.\r\n\r\n#### Step 2. Add Documents\r\n\r\nTo train a Matilda model, you must first addDocuments. \r\nThe method addDocuments takes an array of words.\r\nBut they need not be strings, they can also be numbers.\r\nThey represent the features that the model will be trained on.\r\n\r\n    mM.addDocument([\"Cats\", \"Dogs\", \"Parrots\", \"Fish\"]) \r\n      .addDocument([\"Fish\", \"Sharks\", \"Parrots\", \"Green\"])\r\n      .addDocument([\"Tables\", \"Poker\", \"Green\", \"Sharks\"]);\r\n\r\nBut it also takes an array of arrays.\r\n\r\n    mM.addDocument([[\"Cats\", \"Dogs\", \"Parrots\", \"Fish\"], \r\n                    [\"Fish\", \"Sharks\", \"Parrots\", \"Green\"],\r\n                    [\"Tables\", \"Poker\", \"Green\", \"Sharks\"]])  \r\n\r\nFor natural word pre-rocessing [NaturalNode](https://github.com/NaturalNode/natural) is highly recommended.\r\n\r\n#### Step 3. Train\r\n\r\nNow that the documents have been added, you can train your model.\r\nBy default models are set to five topics.\r\nYou can overide this defaults by using the setNumberOfTopics method.\r\n\r\n   mM.setNumberOfTopics(3);\r\n\r\nIt looks like everything is good to go. \r\nTime to train.\r\nTrain is a method which takes a number which represents the number of iterations.\r\nIt is recommended that at least 50 iterations be made, but for this simple example 5 will do.\r\n\r\n    mM.train(5);\r\n\r\n__WARNING:__ Setting the Model's Topic Count _after_ training will erase all training.\r\n\r\n#### Step 4. Wait\r\n\r\nIt isn't all magic.\r\n\r\n#### Step 5. Enjoy\r\n\r\nThere are a number of features that can be drawn from the training.\r\nA Topic by Topic matrix of correlations may be obtained by calling the topicCorrelations method. \r\n\r\n    mM.topicCorrelations();\r\n\r\nYou can get back the documents containing their respective features, and their topic proportions.\r\n\r\n    mM.getDocuments();\r\n\r\nYou can get an object containing all the Topics, and their words.\r\n\r\n    mM.getTopics();\r\n\r\nYou can even look over the words themselves and their topic memberships.\r\n\r\n    mM.getVocabulary();\r\n\r\n#### Also Chains!\r\nDon't forget, this is a fluent library. You can chain things.\r\n\r\n    mM.setNumberOfTopics(3)\r\n      .addDocument([\"Cats\", \"Dogs\", \"Parrots\", \"Fish\"]) \r\n      .addDocument([\"Fish\", \"Sharks\", \"Parrots\", \"Green\"])\r\n      .addDocument([\"Tables\", \"Poker\", \"Green\", \"Sharks\"])\r\n    \r\n    var topicMatrix = mM.train(5).topicCorrelations()\r\n\r\n### Where is α and β?\r\n\r\nThe smoothing factors of LDA are at present automated.\r\n\r\n## Roadmap\r\n* v0.0.1\r\n  - Output Words by Topic\r\n  - Read from files\r\n* v0.0.2\r\n  - Simplified Belief Propagation\r\n* v0.0.3\r\n  - Saving to JSON\r\n  - Loading from JSON\r\n  - Fast Gibbs Sampling\r\n* v0.0.4\r\n  - Fast Belief Propagation\r\n  - Online Fast Gibbs Sampling\r\n* v0.0.5\r\n  - Online Fast Belief Propagation\r\n* v0.1.0\r\n  - Relational Topic Model (RTM)\r\n  - Author Topic Model (ATM)\r\n  - Topic User Community Model (TUCM)\r\n\r\n## Acknowledgements\r\nMatilda.js is based on [LDAjs](https://github.com/mimno/jsLDA), [Gensim](http://radimrehurek.com/gensim/), and [Mallet](http://mallet.cs.umass.edu/), and inspired by the works of [David Mimno](http://www.cs.princeton.edu/~mimno/), [Ted Underwood](http://tedunderwood.com/), [David Blei](http://www.cs.princeton.edu/~blei/), [Roald Dahl](http://www.roalddahl.com/), and [Sir John Carden](http://www.tankmuseum.org/ixbin/indexplus?_IXSS_=_IXMENU_%3dVehicles%26ALL%3dmatilda%26_IXACTION_%3dsummary%26%252asform%3d%252fsearch_form%252fbovtm_combined%26_IXSESSION_%3d3N23FDeXD_4%26TYPE%3darticle%26_IXFPFX_%3dtemplates%252fsummary%252f&_IXFIRST_=12&_IXSPFX_=templates/full/tvod/t&_IXMAXHITS_=1&submit-button=summary&_IXSESSION_=3N23FDeXD_4&_IXMENU_=Vehicles).\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}